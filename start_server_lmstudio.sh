#!/bin/bash

echo "================================================================"
echo "     Autonomous GPT OSS 20B MCP Server - LM Studio Version"
echo "================================================================"
echo

# –ü—Ä–æ–≤–µ—Ä–∫–∞ Python
echo "[1/5] Checking Python installation..."
if ! command -v python3 &> /dev/null; then
    echo "[ERROR] Python3 not found! Installing..."
    sudo apt update && sudo apt install python3 python3-pip python3-venv python3-tk -y
fi
echo "[OK] Python found"

# –ü—Ä–æ–≤–µ—Ä–∫–∞ curl
if ! command -v curl &> /dev/null; then
    echo "Installing curl..."
    sudo apt install curl -y
fi

# –ü—Ä–æ–≤–µ—Ä–∫–∞ LM Studio API
echo "[2/5] Checking LM Studio server..."
if ! curl -s http://localhost:1234/v1/models > /dev/null 2>&1; then
    echo "[ERROR] LM Studio server not responding!"
    echo
    echo "Please ensure:"
    echo "1. LM Studio is running"
    echo "2. GPT OSS 20B model is downloaded and loaded"
    echo "3. Local server is started on port 1234"
    echo "4. Server tab shows 'Server Running'"
    echo
    echo "To fix this:"
    echo "- Open LM Studio"
    echo "- Go to 'Local Server' tab"
    echo "- Select 'openai/gpt-oss-20b' model"
    echo "- Click 'Start Server'"
    echo
    exit 1
fi
echo "[OK] LM Studio server is running"

# –ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏
echo "[3/5] Checking GPT OSS 20B model availability..."
if ! curl -s -X POST http://localhost:1234/v1/chat/completions \
     -H "Content-Type: application/json" \
     -d '{"model":"gpt-oss-20b","messages":[{"role":"user","content":"test"}],"max_tokens":5}' > /dev/null 2>&1; then
    echo "[WARNING] GPT OSS 20B model may not be properly loaded"
    echo "Please check LM Studio and ensure:"
    echo "- The model is fully downloaded"
    echo "- The model is selected and loaded"
    echo "- Server shows 'Model loaded' status"
fi
echo "[OK] Model appears to be responding"

# –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π Python
echo "[4/5] Installing Python dependencies..."
pip3 install --quiet psutil requests asyncio

# –ü—Ä–æ–≤–µ—Ä–∫–∞ MCP
if ! python3 -c "import mcp" 2>/dev/null; then
    echo "Installing MCP library..."
    pip3 install mcp
fi

echo "[5/5] Configuring LM Studio mode..."

echo
echo "================================================================"
echo "                    STARTING MCP SERVER"
echo "================================================================"
echo
echo "üéõÔ∏è Using LM Studio backend instead of Ollama"
echo "üéÆ Control Center GUI will open automatically"
echo "üé≠ Emotional Display window will appear"
echo "üß† Fine-tuning interface available with LM Studio integration"
echo "üö® DO NOT enable unrestricted access unless testing!"
echo
echo "LM Studio Configuration:"
echo "- Server URL: http://localhost:1234"
echo "- API Version: OpenAI Compatible v1"
echo "- Model: GPT OSS 20B"
echo
echo "Press Ctrl+C to stop the server"
echo

# –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π –æ–∫—Ä—É–∂–µ–Ω–∏—è –¥–ª—è LM Studio
export LM_STUDIO_MODE=1
export LM_STUDIO_URL=http://localhost:1234

# –ó–∞–ø—É—Å–∫ –æ—Å–Ω–æ–≤–Ω–æ–≥–æ —Å–µ—Ä–≤–µ—Ä–∞
python3 main.py

echo
echo "Server stopped."
